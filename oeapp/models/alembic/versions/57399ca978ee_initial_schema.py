"""
Initial schema

Revision ID: 57399ca978ee
Revises:
Create Date: 2025-11-20 16:44:31.177403

"""

import contextlib
from typing import TYPE_CHECKING

import sqlalchemy as sa
from alembic import op

if TYPE_CHECKING:
    from collections.abc import Sequence

# revision identifiers, used by Alembic.
revision: str = "57399ca978ee"
down_revision: str | Sequence[str] | None = None
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:  # noqa: PLR0915
    """
    Upgrade schema.
    """
    # ### commands auto generated by Alembic - please adjust! ###
    # Drop audit_log table if it exists (we don't have a model for it)
    # In batch mode, Alembic will handle missing tables gracefully
    with contextlib.suppress(Exception):
        with op.batch_alter_table("audit_log", schema=None) as batch_op:
            with contextlib.suppress(Exception):
                batch_op.drop_index(batch_op.f("idx_audit_entity"))
            with contextlib.suppress(Exception):
                batch_op.drop_index(batch_op.f("idx_audit_timestamp"))
        op.drop_table("audit_log")
    with op.batch_alter_table("annotations", schema=None) as batch_op:
        batch_op.alter_column("token_id", existing_type=sa.INTEGER(), nullable=False)
        batch_op.alter_column(
            "pos", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
        )
        batch_op.alter_column(
            "gender", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
        )
        batch_op.alter_column(
            "number", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
        )
        batch_op.alter_column(
            "case", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
        )
        batch_op.alter_column(
            "declension",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "article_type",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "pronoun_type",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_class",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_tense",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_person",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_mood",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_aspect",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_form",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "prep_case",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "uncertain",
            existing_type=sa.BOOLEAN(),
            nullable=False,
            existing_server_default=sa.text("0"),
        )
        batch_op.alter_column(
            "alternatives_json",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "last_inferred_json",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "updated_at",
            existing_type=sa.TIMESTAMP(),
            type_=sa.DateTime(),
            nullable=False,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.drop_index(batch_op.f("idx_annotations_pos"))
        batch_op.drop_index(batch_op.f("idx_annotations_uncertain"))
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.create_foreign_key(
            None, "tokens", ["token_id"], ["id"], ondelete="CASCADE"
        )
        batch_op.create_index("idx_annotations_pos", ["pos"])
        batch_op.create_index("idx_annotations_uncertain", ["uncertain"])

    with op.batch_alter_table("notes", schema=None) as batch_op:
        batch_op.alter_column(
            "id", existing_type=sa.INTEGER(), nullable=False, autoincrement=True
        )
        batch_op.alter_column(
            "note_text_md",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=False,
        )
        batch_op.alter_column(
            "note_type",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=False,
        )
        batch_op.alter_column(
            "created_at",
            existing_type=sa.TIMESTAMP(),
            type_=sa.DateTime(),
            nullable=False,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "updated_at",
            existing_type=sa.TIMESTAMP(),
            type_=sa.DateTime(),
            nullable=False,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.drop_index(batch_op.f("idx_notes_sentence"))
        batch_op.drop_index(batch_op.f("idx_notes_token"))
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.create_foreign_key(
            None, "tokens", ["end_token"], ["id"], ondelete="CASCADE"
        )
        batch_op.create_foreign_key(
            None, "tokens", ["start_token"], ["id"], ondelete="CASCADE"
        )
        batch_op.create_foreign_key(
            None, "sentences", ["sentence_id"], ["id"], ondelete="CASCADE"
        )
        batch_op.create_index("idx_notes_sentence", ["sentence_id"])
        batch_op.create_index("idx_notes_token", ["start_token"])

    with op.batch_alter_table("projects", schema=None) as batch_op:
        batch_op.alter_column(
            "id", existing_type=sa.INTEGER(), nullable=False, autoincrement=True
        )
        batch_op.alter_column(
            "name", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=False
        )
        batch_op.alter_column(
            "created_at",
            existing_type=sa.TIMESTAMP(),
            type_=sa.DateTime(),
            nullable=False,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "updated_at",
            existing_type=sa.TIMESTAMP(),
            type_=sa.DateTime(),
            nullable=False,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )

    with op.batch_alter_table("sentences", schema=None) as batch_op:
        batch_op.alter_column(
            "id", existing_type=sa.INTEGER(), nullable=False, autoincrement=True
        )
        batch_op.alter_column(
            "text_oe",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=False,
        )
        batch_op.alter_column(
            "text_modern",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "created_at",
            existing_type=sa.TIMESTAMP(),
            type_=sa.DateTime(),
            nullable=False,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "updated_at",
            existing_type=sa.TIMESTAMP(),
            type_=sa.DateTime(),
            nullable=False,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.drop_index(batch_op.f("idx_sentences_project_order"))
        batch_op.create_unique_constraint(
            "uq_sentences_project_order", ["project_id", "display_order"]
        )
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.create_foreign_key(
            None, "projects", ["project_id"], ["id"], ondelete="CASCADE"
        )
        batch_op.create_index(
            "idx_sentences_project_order", ["project_id", "display_order"]
        )

    with op.batch_alter_table("tokens", schema=None) as batch_op:
        batch_op.alter_column(
            "id", existing_type=sa.INTEGER(), nullable=False, autoincrement=True
        )
        batch_op.alter_column(
            "surface",
            existing_type=sa.TEXT(),
            type_=sa.String(),
            existing_nullable=False,
        )
        batch_op.alter_column(
            "lemma", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
        )
        batch_op.alter_column(
            "created_at",
            existing_type=sa.TIMESTAMP(),
            type_=sa.DateTime(),
            nullable=False,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "updated_at",
            existing_type=sa.TIMESTAMP(),
            type_=sa.DateTime(),
            nullable=False,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.drop_index(batch_op.f("idx_tokens_sentence_order"))
        batch_op.create_unique_constraint(
            "uq_tokens_sentence_order", ["sentence_id", "order_index"]
        )
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.create_foreign_key(
            None, "sentences", ["sentence_id"], ["id"], ondelete="CASCADE"
        )
        batch_op.create_index(
            "idx_tokens_sentence_order", ["sentence_id", "order_index"]
        )

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("tokens", schema=None) as batch_op:
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.create_foreign_key(None, "sentences", ["sentence_id"], ["id"])
        batch_op.drop_constraint("uq_tokens_sentence_order", type_="unique")
        batch_op.create_index(
            batch_op.f("idx_tokens_sentence_order"),
            ["sentence_id", "order_index"],
            unique=False,
        )
        batch_op.alter_column(
            "updated_at",
            existing_type=sa.DateTime(),
            type_=sa.TIMESTAMP(),
            nullable=True,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "created_at",
            existing_type=sa.DateTime(),
            type_=sa.TIMESTAMP(),
            nullable=True,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "lemma", existing_type=sa.String(), type_=sa.TEXT(), existing_nullable=True
        )
        batch_op.alter_column(
            "surface",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=False,
        )
        batch_op.alter_column(
            "id", existing_type=sa.INTEGER(), nullable=True, autoincrement=True
        )

    with op.batch_alter_table("sentences", schema=None) as batch_op:
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.create_foreign_key(None, "projects", ["project_id"], ["id"])
        batch_op.drop_constraint("uq_sentences_project_order", type_="unique")
        batch_op.create_index(
            batch_op.f("idx_sentences_project_order"),
            ["project_id", "display_order"],
            unique=False,
        )
        batch_op.alter_column(
            "updated_at",
            existing_type=sa.DateTime(),
            type_=sa.TIMESTAMP(),
            nullable=True,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "created_at",
            existing_type=sa.DateTime(),
            type_=sa.TIMESTAMP(),
            nullable=True,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "text_modern",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "text_oe",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=False,
        )
        batch_op.alter_column(
            "id", existing_type=sa.INTEGER(), nullable=True, autoincrement=True
        )

    with op.batch_alter_table("projects", schema=None) as batch_op:
        batch_op.alter_column(
            "updated_at",
            existing_type=sa.DateTime(),
            type_=sa.TIMESTAMP(),
            nullable=True,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "created_at",
            existing_type=sa.DateTime(),
            type_=sa.TIMESTAMP(),
            nullable=True,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "name", existing_type=sa.String(), type_=sa.TEXT(), existing_nullable=False
        )
        batch_op.alter_column(
            "id", existing_type=sa.INTEGER(), nullable=True, autoincrement=True
        )

    with op.batch_alter_table("notes", schema=None) as batch_op:
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.create_foreign_key(None, "sentences", ["sentence_id"], ["id"])
        batch_op.create_foreign_key(None, "tokens", ["start_token"], ["id"])
        batch_op.create_foreign_key(None, "tokens", ["end_token"], ["id"])
        batch_op.create_index(
            batch_op.f("idx_notes_token"), ["start_token"], unique=False
        )
        batch_op.create_index(
            batch_op.f("idx_notes_sentence"), ["sentence_id"], unique=False
        )
        batch_op.alter_column(
            "updated_at",
            existing_type=sa.DateTime(),
            type_=sa.TIMESTAMP(),
            nullable=True,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "created_at",
            existing_type=sa.DateTime(),
            type_=sa.TIMESTAMP(),
            nullable=True,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "note_type",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=False,
        )
        batch_op.alter_column(
            "note_text_md",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=False,
        )
        batch_op.alter_column(
            "id", existing_type=sa.INTEGER(), nullable=True, autoincrement=True
        )

    with op.batch_alter_table("annotations", schema=None) as batch_op:
        batch_op.drop_constraint(None, type_="foreignkey")
        batch_op.create_foreign_key(None, "tokens", ["token_id"], ["id"])
        batch_op.create_index(
            batch_op.f("idx_annotations_uncertain"), ["uncertain"], unique=False
        )
        batch_op.create_index(batch_op.f("idx_annotations_pos"), ["pos"], unique=False)
        batch_op.alter_column(
            "updated_at",
            existing_type=sa.DateTime(),
            type_=sa.TIMESTAMP(),
            nullable=True,
            existing_server_default=sa.text("(CURRENT_TIMESTAMP)"),
        )
        batch_op.alter_column(
            "last_inferred_json",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "alternatives_json",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "uncertain",
            existing_type=sa.BOOLEAN(),
            nullable=True,
            existing_server_default=sa.text("0"),
        )
        batch_op.alter_column(
            "prep_case",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_form",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_aspect",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_mood",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_tense",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "verb_class",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "pronoun_type",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "article_type",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "declension",
            existing_type=sa.String(),
            type_=sa.TEXT(),
            existing_nullable=True,
        )
        batch_op.alter_column(
            "case", existing_type=sa.String(), type_=sa.TEXT(), existing_nullable=True
        )
        batch_op.alter_column(
            "number", existing_type=sa.String(), type_=sa.TEXT(), existing_nullable=True
        )
        batch_op.alter_column(
            "gender", existing_type=sa.String(), type_=sa.TEXT(), existing_nullable=True
        )
        batch_op.alter_column(
            "pos", existing_type=sa.String(), type_=sa.TEXT(), existing_nullable=True
        )
        batch_op.alter_column("token_id", existing_type=sa.INTEGER(), nullable=True)

    op.create_table(
        "audit_log",
        sa.Column("id", sa.INTEGER(), nullable=True),
        sa.Column(
            "timestamp",
            sa.TIMESTAMP(),
            server_default=sa.text("(CURRENT_TIMESTAMP)"),
            nullable=True,
        ),
        sa.Column("entity_type", sa.TEXT(), nullable=False),
        sa.Column("entity_id", sa.INTEGER(), nullable=False),
        sa.Column("action", sa.TEXT(), nullable=False),
        sa.Column("diff_json", sa.TEXT(), nullable=True),
        sa.CheckConstraint("action IN ('INSERT','UPDATE','DELETE')"),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("audit_log", schema=None) as batch_op:
        batch_op.create_index(
            batch_op.f("idx_audit_timestamp"), ["timestamp"], unique=False
        )
        batch_op.create_index(
            batch_op.f("idx_audit_entity"), ["entity_type", "entity_id"], unique=False
        )

    # ### end Alembic commands ###
